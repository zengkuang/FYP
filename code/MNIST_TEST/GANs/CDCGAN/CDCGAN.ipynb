{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Deep Convolutional Generative Adversarial Network (CDCGAN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries we will need.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import scipy.misc\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the MNIST dataset. input_data is a library that downloads the dataset and uzips it automatically. It can be acquired Github here: https://gist.github.com/awjuliani/1d21151bc17362bf6738c3dc02f37906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f9584ef0ae80>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n",
      "(55000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFEFJREFUeJzt3X2QXXV9x/H3R0FtQ3jMAoFCUpSCoAVpYOgAEWoFwhRJxtIKiPiAYRiZAVL/QASMhgR1RCHTDhglBVRwEIhQBlSMyEO1lEchZANYigES8wAlBFAQ8u0f5+yPy5L9nXv33r3n7ubzmtnZ3fs995zvnmQ/93fO+e25igjMzADeVncDZtY7HAhmljgQzCxxIJhZ4kAws8SBYGaJA2EQSbMlfb+mbe8m6cVOL7spkfR9SbM7/VxJJ0m6pZ3eRoMxHQiS3inpMkm/k7Re0gOSpjXUD5X09DDXvaukFxs+QtJLDd8f0uo6I+KJiNii08u2qvzFeLXcZ+slPSxprqQtW1jH05IObaOHuyR9crjP77SIuCIiplUv+WaS3iXpckkvSFop6fSR6K9TxnQgAJsBTwEfBLYCzgWukTS53RVHxPKI2GLgo3x4n4bH7hz8HElvb3e7XTQvIsYDfcBngEOAOyX9Wb1tjTpzgMnArsCHgbMl/X2tHWWM6UCIiJciYnZEPBkRGyLiJuB/gb+RNA64Bdip4VV9p/Kp75B0Zfnq+IikKcPZfvlK+2+SfiLpJeAQSR+R9GC57uWSzm1Y/j2SouH7uyR9WdKvyuV/ImnbVpct658qt7dW0tnNvoJHxB8j4r+Bo4EdgZPK9e0u6TZJz5br/J6krcra1cBOwC3lfp0l6W2SrpX0e0nPS/qlpPcOY582s54+SYvL/XCbpF0anr+XpJ9Lek7SMkkfbXK7J0v6ZUMP8yWtlrRO0kOS9hriqZ8AvhIRz0fEEmAh8MlWf+5uGdOBMJikHYC/Ah6JiJeAacCKhlf1FeWiHwF+CGwN3Aj8axubPR74MjAe+DXwIvBxihHL0cDpkv6h4vknATsA44BZrS4r6f3AfOBjwM4Ur/o7tvJDRMQ6YDHFSAFAwPnARGAvYDeKERgRcRywAphW7tdvls+5Cdi93PYS4Hut9NCgaj0fB84DJgBLB+qSxgO3AlcC2wMnAAsk7dHi9qcBB5Y9bEOxX58bvJCkvnI7v2l4+DfA3i1ur2s2mUCQtDnwA+CKiFhWsfhdEXFzRLxO8Z9pnzY2vSgifl2OUF6JiF9ExJLy+99QBM8HM8+/LCIej4iXgR8B+w5j2WOBH0fEryLiFeCcYf4sK4BtASLisYhYHBGvRsRq4Fu5n6P8eS+PiPUR8UdgNm+M1JrW5Hr+IyL+s/xZzwamSppIEfSPRcSVEfFaRNwH/Bj4x1Z6AP4EbAnsWfa0NCJ+v5HlBg4l1zU8to7ixaEnbRKBIOltFL/YrwKnNfGUxn/cl4F3SdpsmJt/alAvf1sOc9dIWgecTPFK1mwvuROJQy27U2Mf5ejo/5rofbCdKV8JJe0o6RpJz0h6AbiczM8h6e2Svi7piXL535al3M8+3PU0/qzrKH4JdwImAQeVhxrPS3oe+GeKUU7TIuJnwKXAJcAqSZeWo4/BBq4CNZ6M3RJY38r2umnMB4IkAZdRDKM/GhF/aih34089B2/jh8B1wC4RsRXwXYrh90haCfzFwDflq+k2raxAxRWGvwMGTpZ+DXgFeH9EbElxXNz4cwz+uT8BHFWuYyvgPQOrbqWPJtfTeM5gq3K5FRRBsTgitm742CIimnmReJOIuCgi9gPeR3HI9JZDuYhYA6zhzSPMfYBHWt1et4z5QKBI8fcCR0fEHwbVVgHbDZwM65LxwHMR8UdJB1Icf460HwHTJR0o6R3AV5p9oorLZlOAGyj+c19ZlsYDLwHrypN2nx/01FUU5xVoWP4V4Fngz4G5TWx+83L7Ax+bN7meo8uR2DspznPcFRErKc4H7S3peEmblx8HtHoOoXzOAeWo8SWKkefrQyx+JXCupK3LE4+fphhN9aQxHQiSJgGnUBxL/15vXE04AaA8l3A18EQ5hNwps7pOORW4QNJ6iuPba0Z6gxHxEHAmRTCsoPhlepbiF2soZ5c9rgWuAP4LOKg8PwHwJeAAiuH4jRSjnkbzgC+X+/UM4N/Lba+geIX8VROtLwD+0PDxnSbX832KIFgL/DVwYrkf1gFHUJx0XElxiHUB8M4memm0NcWo83ngyXJd3xpi2XMpRiZPAb8ALoiIn7e4ve6JiK5/AEcCj1Ic/51VRw8V/T0JPAw8CNzbA/0sBFYDSxoe25bijPnj5edtWljflsAGisOWkepvNvBMuQ8fBI6qcf/tAtwG9FOEyOnt7sMu9df1fVjHD/924H8ohpPvoLgMs1dd/1mG6PFJYELdfTT0MxXYb9Av3NcHwhQ4C/haxTo+QjHE3oLilbZjQTdEf7OBz9e978peJgL7lV+PBx6jOO5vaR/W0F/X92EdhwwHAL+NYurtqxQn2Y6poY9RIyLu4K3XuY+hGMpTfp5esZoZFMPspylmzh03wv31jIhYGRH3l1+vp3gl3pnW92G3++u6OgJhZ958Ke5pavrhMwL4maT7JM2su5kh7BDFiTLKz9vnFo6IT8UbZ9Y/HBGPd6HH08pZfAsltXRVY6SomLb+AeBuWtyH3TCoP+jyPqwjEDZ2manX7vR6UBSXlKYBn5M0te6GRqFLgHdTnNBdCVxYbzsgaQuKk59nRMQLdfcz2Eb66/o+rCMQnqbhOjHF9fEVQyxbiyinMEcxA28RxWFOr1lVzr6j/Ly65n7eJCJWRcTrEbGB4pxFrfuwvGR5HfCDiLi+fLhn9uHG+qtjH9YRCPcAu0v6y/Ka+McoLlv1BEnjBmadlRN4DqeYL99rbqT8Q6Py8w019vIWA79opRnUuA8bJqf1xxt/VwE9sg+H6q+OfajyzGZXSToKuIjiisPCiGhmkkpXSNqNYlQAxZ9PX1V3fyr+evBQium5qyjmAPyYYg7DrsBy4NiIqOXE3hD9HUox1A2KqzanDByv19DfwRQzLB+muNwKxRyQu+mBfZjp7zi6vA9rCQQz601jeqaimbXGgWBmiQPBzBIHgpklDgQzS2oNhB6eFgy4v3b1cn+93BvU11/dI4Se/kfB/bWrl/vr5d6gpv7qDgQz6yFtTUySdCRwMcWMw+9GxFcrlvcsKLOaRETl/SuHHQgq3oXoMYp3o3ma4m8UjouIpZnnOBDMatJMILRzyOAbnZiNMe0Ewmi40YmZtWC4bz4CTd7opLx80utndM2M9gKhqRudRMQCittp+xyCWY9r55Chp290YmatG/YIISJek3Qa8FPeuNFJz75FlZlV6+oNUnzIYFafkb7saGZjjAPBzBIHgpklDgQzSxwIZpY4EMwscSCYWeJAMLPEgWBmiQPBzBIHgpklDgQzSxwIZpY4EMwscSCYWeJAMLPEgWBmiQPBzBIHgpklDgQzSxwIZpY4EMwscSCYWeJAMLPEgWBmiQPBzBIHgpklDgQzSxwIZpY4EMws2azuBqx3TJo0KVs/+eSTs/UvfvGL2XpEZOtS/t3K+/v7s/VzzjknW1+0aFG2bm0GgqQngfXA68BrETGlE02ZWT06MUI4LCLWdmA9ZlYzn0Mws6TdQAjgZ5LukzSzEw2ZWX3aPWQ4KCJWSNoeuFXSsoi4o3GBMigcFmajQFsjhIhYUX5eDSwCDtjIMgsiYopPOJr1vmEHgqRxksYPfA0cDizpVGNm1n2qujY85BOl3ShGBVAcelwVEXMrnjO8jVlT+vr6svUvfOEL2foJJ5yQrW+33XbZetU8gnbnIVQ9/6mnnsrW999//2x97dqxfbEsIvI7mDbOIUTEE8A+w32+mfUeX3Y0s8SBYGaJA8HMEgeCmSUOBDNLHAhmlgx7HsKwNuZ5CG2put/AnDlzsvW65wGsWbMmW68yYcKEbH3y5MnZ+tKlS7P1vffeu9WWRpVm5iF4hGBmiQPBzBIHgpklDgQzSxwIZpY4EMwscSCYWeJ5CKPIPffck63vt99+2Xq78xCqruMfdthh2Xq79xs4+OCDs/Xbb789W6/6+TfbbGy/TYnnIZhZSxwIZpY4EMwscSCYWeJAMLPEgWBmiQPBzBLPQ+ghe+65Z7ZeNQ/h2Wefzdar7kdQNU/gzDPPzNbPOOOMbH3evHnZ+vLly7P1KlX/lzds2JCtn3rqqdn6ggULWu6pl3gegpm1xIFgZokDwcwSB4KZJQ4EM0scCGaWOBDMLPE8hFGkap5C1TyCdu9HMHPmzGz9kksuydb333//bP3+++/P1mfMmJGtX3vttdl61f/1HXfcMVtvd//VrSPzECQtlLRa0pKGx7aVdKukx8vP27TbrJnVr5lDhsuBIwc9dhawOCJ2BxaX35vZKFcZCBFxB/DcoIePAa4ov74CmN7hvsysBsM9qbhDRKwEKD9v37mWzKwuI35XSUkzgfzZKDPrCcMdIaySNBGg/Lx6qAUjYkFETImIKcPclpl1yXAD4UbgpPLrk4AbOtOOmdWp8pBB0tXAocAESU8DXwK+Clwj6TPAcuDYkWzSCsuWLat1+1X3U3j00Uez9ar7NVTdb+Gss/IXs6reV2Kk52mMBZWBEBHHDVH6UId7MbOaeeqymSUOBDNLHAhmljgQzCxxIJhZ4kAws2TEpy5b90ydOjVbr7qfQtU8g/7+/mx9jz32yNbvvvvubL2vry9br7qfQVX/06ZNy9bNIwQza+BAMLPEgWBmiQPBzBIHgpklDgQzSxwIZpZ4HsIYcvzxx2frn/3sZ7P1qvsJVM0DqHp+1TyDdu9nMH/+/Gy96n0fzCMEM2vgQDCzxIFgZokDwcwSB4KZJQ4EM0scCGaWeB7CJqRqHkHdz7/zzjuz9VmzZmXrnmfQPo8QzCxxIJhZ4kAws8SBYGaJA8HMEgeCmSUOBDNLPA9hDLnqqquy9UmTJmXrEyZMyNar3tdh3Lhx2XqV8847L1v3PIORVzlCkLRQ0mpJSxoemy3pGUkPlh9HjWybZtYNzRwyXA4cuZHHvxUR+5YfN3e2LTOrQ2UgRMQdwHNd6MXMatbOScXTJD1UHlJs07GOzKw2ww2ES4B3A/sCK4ELh1pQ0kxJ90q6d5jbMrMuGVYgRMSqiHg9IjYA3wEOyCy7ICKmRMSU4TZpZt0xrECQNLHh2xnAkqGWNbPRQ03ca/9q4FBgArAK+FL5/b5AAE8Cp0TEysqNSe39Qb3Vqmoewvnnn5+tT58+PVt/4IEHsvVp06Zl61Xv27Cpi4j8G1/QxMSkiDhuIw9fNqyOzKyneeqymSUOBDNLHAhmljgQzCxxIJhZ4kAws6RyHkJHNzbK5yH09fVl62vWrOlSJ6PTLbfckq0fccQR2XrV+zJcdNFFLfe0KWlmHoJHCGaWOBDMLHEgmFniQDCzxIFgZokDwcwSB4KZJX5fhgZTp07N1i+8cMg7xQGwbNmybP3EE09suaexZO7cudn64Ycfnq3vsccenWzHNsIjBDNLHAhmljgQzCxxIJhZ4kAws8SBYGaJA8HMkk1qHkLV/QwuvfTSbH316tXZ+qY+z2DcuHHZ+re//e1sXar8c30bYR4hmFniQDCzxIFgZokDwcwSB4KZJQ4EM0scCGaWbFLzEGbMmJGtV/29/e23397JdkadPffcM1u/7rrrsvWq/Vv1HiFV95uw9lWOECTtIuk2Sf2SHpF0evn4tpJulfR4+XmbkW/XzEZSM4cMrwH/EhHvBQ4EPidpL+AsYHFE7A4sLr83s1GsMhAiYmVE3F9+vR7oB3YGjgGuKBe7Apg+Uk2aWXe0dFJR0mTgA8DdwA4RsRKK0AC273RzZtZdTZ9UlLQFcB1wRkS80OwfokiaCcwcXntm1k1NjRAkbU4RBj+IiOvLh1dJmljWJwIb/VPAiFgQEVMiYkonGjazkdPMVQYBlwH9EfHNhtKNwEnl1ycBN3S+PTPrJlVd+5V0MHAn8DCwoXz4bIrzCNcAuwLLgWMj4rmKdeU3NsKqrqP39/dn60uXLs3WL7jggrbWf99992XrVSZNmpStH3LIIdl61TyN6dPz542rDiOr/q9dfPHF2fqsWbOydcuLiMrj/MpzCBFxFzDUij7UalNm1rs8ddnMEgeCmSUOBDNLHAhmljgQzCxxIJhZUjkPoaMbq3keQpVrr702Wx/p6/APPPBAtl5l1113zda32267bL3d/queP3fu3Gx9/vz52fratWuzdctrZh6CRwhmljgQzCxxIJhZ4kAws8SBYGaJA8HMEgeCmSWeh9Cgr68vW7/55puz9SlT8jeF2rBhQ7Y+0vMAqp7/8ssvZ+tV74swb968bH3RokXZuo0sz0Mws5Y4EMwscSCYWeJAMLPEgWBmiQPBzBIHgpklnofQggkTJmTrc+bMaWv9M2fm3/Hu+uuvz9bbvV9A1fsiVM1DsN7meQhm1hIHgpklDgQzSxwIZpY4EMwscSCYWeJAMLPE8xDMNhEdmYcgaRdJt0nql/SIpNPLx2dLekbSg+XHUZ1o2szqUzlCkDQRmBgR90saD9wHTAf+CXgxIr7R9MY8QjCrTTMjhM2aWMlKYGX59XpJ/cDO7bdnZr2mpZOKkiYDHwDuLh86TdJDkhZK2maI58yUdK+ke9vq1MxGXNMnFSVtAdwOzI2I6yXtAKwFAphDcVjx6Yp1+JDBrCbNHDI0FQiSNgduAn4aEd/cSH0ycFNEvK9iPQ4Es5p06iqDgMuA/sYwKE82DpgBLBlOk2bWO5q5ynAwcCfwMDDwxgJnA8cB+1IcMjwJnFKegMytyyMEs5p07JChUxwIZvXxDVLMrCUOBDNLHAhmljgQzCxxIJhZ4kAws8SBYGaJA8HMEgeCmSUOBDNLHAhmljgQzCxxIJhZ4kAws6TyJqsdthb4XcP3E8rHepX7a08v99fLvUHn+5vUzEJdvR/CWzYu3RsRU2proIL7a08v99fLvUF9/fmQwcwSB4KZJXUHwoKat1/F/bWnl/vr5d6gpv5qPYdgZr2l7hGCmfUQB4KZJQ4EM0scCGaWOBDMLPl/8rjMNZlWtocAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print out several data in mnist\n",
    "trainimg = mnist.train.images\n",
    "train_y = mnist.train.labels\n",
    "nsample = 1\n",
    "randidx = np.random.randint(trainimg.shape[0], size=nsample)\n",
    "\n",
    "train_x = np.reshape(trainimg,(trainimg.shape[0],28,28))\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "for i in [0, 1, 2]:\n",
    "    curr_img   = np.reshape(trainimg[i, :], (28, 28)) # 28 by 28 matrix \n",
    "    curr_label = np.argmax(train_y[i] ) # Label\n",
    "    plt.matshow(curr_img, cmap=plt.get_cmap('gray'))\n",
    "    plt.title(\"\" + str(i + 1) + \"th Training Data \" \n",
    "              + \"Label is \" + str(curr_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function performns a leaky relu activation, which is needed for the discriminator network.\n",
    "NUM_LABELS = 47\n",
    "rnd = np.random.RandomState(123)\n",
    "tf.set_random_seed(123)\n",
    "batch_size = 128\n",
    "IMG_CHN = 1\n",
    "\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "     with tf.variable_scope(name):\n",
    "         f1 = 0.5 * (1 + leak)\n",
    "         f2 = 0.5 * (1 - leak)\n",
    "         return f1 * x + f2 * abs(x)\n",
    "    \n",
    "#The below functions are taken from carpdem20's implementation https://github.com/carpedm20/DCGAN-tensorflow\n",
    "#They allow for saving sample images from the generator to follow progress\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
    "\n",
    "    return img\n",
    "\n",
    "def upsample(input, name, factor=[2,2]):\n",
    "    size = [int(input.shape[1] * factor[0]), int(input.shape[2] * factor[1])]\n",
    "    with tf.name_scope(name):\n",
    "        out = tf.image.resize_nearest_neighbor(input, size=size, align_corners=False, name=None)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE as image feature extractor for condition input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cae_encoder(x, reuse = False):\n",
    "    \n",
    "    c1 = slim.convolution2d(x, 32, [3,3], stride=[1,1], padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='conv1')\n",
    "    \n",
    "    p1 = slim.max_pool2d(c1, [2, 2], scope='pool1')\n",
    "    \n",
    "    c2 = slim.convolution2d(p1, 64, [3,3], stride=[2,2], padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='conv2')\n",
    "    \n",
    "    c3 = slim.convolution2d(c2, 64, [3,3], stride=[1,1], padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='conv3')\n",
    "\n",
    "    e_out = slim.max_pool2d(c3, [2, 2], scope='pool2')\n",
    "    \n",
    "    return e_out\n",
    "\n",
    "def cae_decoder(f, reuse = False):\n",
    "    \n",
    "    up1 = upsample(f, name = \"up1\")\n",
    "\n",
    "    dc_1 = slim.convolution2d_transpose(\\\n",
    "        up1,num_outputs=64, kernel_size=[3,3],stride=[1,1],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='dconv_1' )\n",
    "\n",
    "    dc_2 = slim.convolution2d_transpose(\\\n",
    "        dc_1, num_outputs=32, kernel_size=[3,3],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='dconv_2' )\n",
    "\n",
    "\n",
    "    up2 = upsample(dc_2, name = \"up2\")\n",
    "\n",
    "    dc_3 = slim.convolution2d_transpose(\\\n",
    "        up2, num_outputs=IMG_CHN, kernel_size=[3,3],stride=[1,1],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.sigmoid,scope='dconv_3' )\n",
    "\n",
    "    return dc_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network\n",
    "\n",
    "The generator takes a vector of random numbers and transforms it into a 32x32 image. Each layer in the network involves a strided  transpose convolution, batch normalization, and rectified nonlinearity. Tensorflow's slim library allows us to easily define each of these layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, c):\n",
    "    \n",
    "    with tf.variable_scope(\"gan\"):\n",
    "    \n",
    "        zcP = tf.concat([z, c],1)\n",
    "\n",
    "        g_in = slim.fully_connected(zcP,4*4*128,normalizer_fn= slim.batch_norm,\\\n",
    "            activation_fn=tf.nn.relu,scope='g_project')\n",
    "\n",
    "        g_in_Con = tf.reshape(g_in,[-1,4,4,128])\n",
    "\n",
    "        gen1 = slim.convolution2d_transpose(\\\n",
    "            g_in_Con,num_outputs=64,kernel_size=[5,5],stride=[2,2],\\\n",
    "            padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "            activation_fn=tf.nn.relu,scope='g_conv1')\n",
    "\n",
    "        gen2 = slim.convolution2d_transpose(\\\n",
    "            gen1,num_outputs=32,kernel_size=[5,5],stride=[2,2],\\\n",
    "            padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "            activation_fn=tf.nn.relu,scope='g_conv2')\n",
    "\n",
    "        gen3 = slim.convolution2d_transpose(\\\n",
    "            gen2,num_outputs=16,kernel_size=[5,5],stride=[2,2],\\\n",
    "            padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "            activation_fn=tf.nn.relu,scope='g_conv3')\n",
    "\n",
    "        g_out = slim.convolution2d_transpose(\\\n",
    "            gen3,num_outputs=1,kernel_size=[32,32],padding=\"SAME\",\\\n",
    "            biases_initializer=None,activation_fn=tf.nn.tanh,\\\n",
    "            scope='g_out')\n",
    "\n",
    "    return g_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network\n",
    "The discriminator network takes as input a 32x32 image and transforms it into a single valued probability of being generated from real-world data. Again we use tf.slim to define the convolutional layers, batch normalization, and weight initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(img, c, reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(\"gan\"):\n",
    "\n",
    "        dis1 = slim.convolution2d(img,16,[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "            biases_initializer=None,activation_fn=lrelu,\\\n",
    "            reuse=reuse,scope='d_conv1')\n",
    "\n",
    "        dis2 = slim.convolution2d(dis1,32,[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "            normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "            reuse=reuse,scope='d_conv2')\n",
    "\n",
    "        dis3 = slim.convolution2d(dis2,32,[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "            normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "            reuse=reuse,scope='d_conv3')\n",
    "\n",
    "        d_fc1 = slim.fully_connected(slim.flatten(dis1),512,activation_fn=tf.nn.relu,\\\n",
    "            reuse=reuse,scope='d_fc1')\n",
    "\n",
    "        d_combined =  tf.concat([d_fc1, c],1)\n",
    "\n",
    "\n",
    "        d_fc2 = slim.fully_connected(slim.flatten(d_combined),128,activation_fn=tf.nn.relu,\\\n",
    "            reuse=reuse,scope='d_fc2')\n",
    "\n",
    "        d_out= slim.fully_connected(slim.flatten(d_combined),1,activation_fn=tf.nn.sigmoid,\\\n",
    "            reuse=reuse,scope='d_out')\n",
    "\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../CAE/models\\model-4000.cptk\n",
      "CAE restored.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "z_size = 100 #Size of z vector used for generator.\n",
    "\n",
    "#These two placeholders are used for input into the generator and discriminator, respectively.\n",
    "\n",
    "z_in = tf.placeholder(shape=[None,z_size],dtype=tf.float32) #Random vector\n",
    "c_in = tf.placeholder(shape = [None,32,32,IMG_CHN],dtype = tf.float32) # conditional input\n",
    "real_in = tf.placeholder(shape=[None,32,32,IMG_CHN],dtype=tf.float32) #Real images\n",
    "\n",
    "'''\n",
    "Define GAN graph\n",
    "'''\n",
    "fx = cae_encoder(c_in)\n",
    "model_directory = '../../CAE/models' #Directory to load trained model from.\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    #Reload CAE the model\n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    print(\"CAE restored.\")\n",
    "    \n",
    "c_in_flat = tf.layers.Flatten()(fx)\n",
    "Gz = generator(z_in, c_in_flat) #Generates images from random z vectors\n",
    "Dx = discriminator(real_in, c_in_flat) #Produces probabilities for real images\n",
    "Dg = discriminator(Gz,c_in_flat,reuse=True) #Produces probabilities for generator images\n",
    "\n",
    "#These functions together define the optimization objective of the GAN.\n",
    "d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg)) #This optimizes the discriminator.\n",
    "g_loss = -tf.reduce_mean(tf.log(Dg)) #This optimizes the generator.\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "#The below code is responsible for applying gradient descent to update the GAN.\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0005,beta1=0.5)\n",
    "trainerG = tf.train.AdamOptimizer(learning_rate=0.0005,beta1=0.5)\n",
    "d_grads = trainerD.compute_gradients(d_loss,tvars[9:]) #Only update the weights for the discriminator network.\n",
    "g_grads = trainerG.compute_gradients(g_loss,tvars[0:9]) #Only update the weights for the generator network.\n",
    "\n",
    "update_D = trainerD.apply_gradients(d_grads)\n",
    "update_G = trainerG.apply_gradients(g_grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [4096,512] and type float\n\t [[Node: gan/d_fc1/weights/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [4096,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'gan/d_fc1/weights/Adam/Initializer/zeros', defined at:\n  File \"c:\\program files\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\program files\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"c:\\program files\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-2b45e58feabe>\", line 45, in <module>\n    update_D = trainerD.apply_gradients(d_grads)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 600, in apply_gradients\n    self._create_slots(var_list)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 1150, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 181, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 155, in create_slot_with_initializer\n    dtype)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 343, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 770, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1626, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3169, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [4096,512] and type float\n\t [[Node: gan/d_fc1/weights/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [4096,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [4096,512] and type float\n\t [[Node: gan/d_fc1/weights/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [4096,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6aa42a4de3d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgan_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [4096,512] and type float\n\t [[Node: gan/d_fc1/weights/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [4096,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'gan/d_fc1/weights/Adam/Initializer/zeros', defined at:\n  File \"c:\\program files\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\program files\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"c:\\program files\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-2b45e58feabe>\", line 45, in <module>\n    update_D = trainerD.apply_gradients(d_grads)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 600, in apply_gradients\n    self._create_slots(var_list)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 1150, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 181, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 155, in create_slot_with_initializer\n    dtype)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 343, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 770, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1626, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3169, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [4096,512] and type float\n\t [[Node: gan/d_fc1/weights/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [4096,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 #Size of image batch to apply at each iteration.\n",
    "iterations = 500000 #Total number of iterations to use.\n",
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to save trained model to.\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "GAN_list = tf.get_collection(\n",
    "    tf.GraphKeys.GLOBAL_VARIABLES, \n",
    "    scope=\"gan\"\n",
    ")\n",
    "\n",
    "gan_init = tf.variables_initializer(GAN_list)\n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(gan_init)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        print(i)\n",
    "        zs = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate a random z batch\n",
    "        xs,_ = mnist.train.next_batch(batch_size) #Draw a sample batch from MNIST dataset.\n",
    "        xs = (np.reshape(xs,[batch_size,28,28,1]) - 0.5) * 2.0 #Transform it to be between -1 and 1\n",
    "        xs = np.lib.pad(xs, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1)) #Pad the images so the are 32x32\n",
    "        \n",
    "        _,dLoss = sess.run([update_D,d_loss],feed_dict={z_in:zs,real_in:xs, c_in:xs }) #Update the discriminator\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs, c_in:xs}) #Update the generator, twice for good measure.\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs, c_in:xs})\n",
    "        \n",
    "        break\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Gen Loss: \" + str(gLoss) + \" Disc Loss: \" + str(dLoss))\n",
    "            z2 = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate another z batch\n",
    "            newZ = sess.run(Gz,feed_dict={z_in:z2, c_in:xs}) #Use new z to get sample images from generator.\n",
    "            if not os.path.exists(sample_directory):\n",
    "                os.makedirs(sample_directory)\n",
    "            #Save sample generator images for viewing training progress.\n",
    "            save_images(np.reshape(newZ[0:36],[36,32,32]),[6,6],sample_directory+'/fig'+str(i)+'.png')\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
    "            print(\"Saved Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained network\n",
    "Once we have a trained model saved, we may want to use it to generate new images, and explore the representation it has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to load trained model from.\n",
    "batch_size_sample = 36\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)\n",
    "    #Reload the model.\n",
    "    print 'Loading Model...'\n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    \n",
    "    zs = np.random.uniform(-1.0,1.0,size=[batch_size_sample,z_size]).astype(np.float32) #Generate a random z batch\n",
    "    newZ = sess.run(Gz,feed_dict={z_in:z2}) #Use new z to get sample images from generator.\n",
    "    if not os.path.exists(sample_directory):\n",
    "        os.makedirs(sample_directory)\n",
    "    save_images(np.reshape(newZ[0:batch_size_sample],[36,32,32]),[6,6],sample_directory+'/fig'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
