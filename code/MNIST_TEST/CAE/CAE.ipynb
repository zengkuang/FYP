{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAE Trainer on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import os\n",
    "import shutil\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 47\n",
    "rnd = np.random.RandomState(123)\n",
    "tf.set_random_seed(123)\n",
    "batch_size = 128\n",
    "IMG_CHN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainimg = mnist.train.images\n",
    "train_X = trainimg.reshape([-1,28,28])\n",
    "trainlabel = mnist.train.labels\n",
    "nsample = 1\n",
    "randidx = np.random.randint(trainimg.shape[0], size=nsample)\n",
    "\n",
    "for i in [0, 1, 2]:\n",
    "    curr_img   = np.reshape(trainimg[i, :], (28, 28)) # 28 by 28 matrix \n",
    "    curr_label = np.argmax(trainlabel[i, :] ) # Label\n",
    "    plt.matshow(curr_img, cmap=plt.get_cmap('gray'))\n",
    "    plt.title(\"\" + str(i + 1) + \"th Training Data \" \n",
    "              + \"Label is \" + str(curr_label))\n",
    "IMAGE_SIZE = train_X.shape\n",
    "print(IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define utils\n",
    "#This function performns a leaky relu activation, which is needed for the discriminator network.\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "     with tf.variable_scope(name):\n",
    "         f1 = 0.5 * (1 + leak)\n",
    "         f2 = 0.5 * (1 - leak)\n",
    "         return f1 * x + f2 * abs(x)\n",
    "    \n",
    "#The below functions are taken from carpdem20's implementation https://github.com/carpedm20/DCGAN-tensorflow\n",
    "#They allow for saving sample images from the generator to follow progress\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
    "\n",
    "    return img\n",
    "\n",
    "def upsample(input, name, factor=[2,2]):\n",
    "    size = [int(input.shape[1] * factor[0]), int(input.shape[2] * factor[1])]\n",
    "    with tf.name_scope(name):\n",
    "        out = tf.image.resize_nearest_neighbor(input, size=size, align_corners=False, name=None)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, reuse = False):\n",
    "    \n",
    "    c1 = slim.convolution2d(x, 32, [3,3], stride=[1,1], padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='conv1')\n",
    "    \n",
    "    p1 = slim.max_pool2d(c1, [2, 2], scope='pool1')\n",
    "    \n",
    "    c2 = slim.convolution2d(p1, 64, [3,3], stride=[2,2], padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='conv2')\n",
    "    \n",
    "    c3 = slim.convolution2d(c2, 64, [3,3], stride=[1,1], padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='conv3')\n",
    "\n",
    "    e_out = slim.max_pool2d(c3, [2, 2], scope='pool2')\n",
    "    \n",
    "    print(e_out.shape)\n",
    "    return e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(f, reuse = False):\n",
    "    \n",
    "    up1 = upsample(f, name = \"up1\")\n",
    "\n",
    "    dc_1 = slim.convolution2d_transpose(\\\n",
    "        up1,num_outputs=64, kernel_size=[3,3],stride=[1,1],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='dconv_1' )\n",
    "\n",
    "    dc_2 = slim.convolution2d_transpose(\\\n",
    "        dc_1, num_outputs=32, kernel_size=[3,3],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='dconv_2' )\n",
    "\n",
    "    up2 = upsample(dc_2, name = \"up2\")\n",
    "\n",
    "    dc_3 = slim.convolution2d_transpose(\\\n",
    "        up2, num_outputs=IMG_CHN, kernel_size=[3,3],stride=[1,1],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.sigmoid,scope='dconv_3' )\n",
    "\n",
    "    print(dc_3.shape)\n",
    "    return dc_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4, 4, 64)\n",
      "(?, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#set computational graph\n",
    "\n",
    "tf.reset_default_graph()\n",
    "img_in = tf.placeholder(shape = [None, 32, 32, IMG_CHN], dtype = tf.float32)\n",
    "\n",
    "fx = encoder(img_in)\n",
    "#print(fx.shape)\n",
    "xp = decoder(fx)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(xp, img_in)))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0 reconstructive loss:0.6991549730300903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:10 reconstructive loss:0.5385639667510986\n",
      "iter:20 reconstructive loss:0.5334188938140869\n",
      "iter:30 reconstructive loss:0.529035210609436\n",
      "iter:40 reconstructive loss:0.5234220027923584\n",
      "iter:50 reconstructive loss:0.520530104637146\n",
      "iter:60 reconstructive loss:0.5151888132095337\n",
      "iter:70 reconstructive loss:0.514736533164978\n",
      "iter:80 reconstructive loss:0.5109316110610962\n",
      "iter:90 reconstructive loss:0.506068766117096\n",
      "iter:100 reconstructive loss:0.5008804202079773\n",
      "iter:110 reconstructive loss:0.5022404193878174\n",
      "iter:120 reconstructive loss:0.4984365701675415\n",
      "iter:130 reconstructive loss:0.4930884838104248\n",
      "iter:140 reconstructive loss:0.4934900999069214\n",
      "iter:150 reconstructive loss:0.48814064264297485\n",
      "iter:160 reconstructive loss:0.48563796281814575\n",
      "iter:170 reconstructive loss:0.48195910453796387\n",
      "iter:180 reconstructive loss:0.4817362427711487\n",
      "iter:190 reconstructive loss:0.47923800349235535\n",
      "iter:200 reconstructive loss:0.4783852696418762\n",
      "iter:210 reconstructive loss:0.4760950207710266\n",
      "iter:220 reconstructive loss:0.4692513942718506\n",
      "iter:230 reconstructive loss:0.46859702467918396\n",
      "iter:240 reconstructive loss:0.4691580533981323\n",
      "iter:250 reconstructive loss:0.4625987112522125\n",
      "iter:260 reconstructive loss:0.46311599016189575\n",
      "iter:270 reconstructive loss:0.4605271518230438\n",
      "iter:280 reconstructive loss:0.46133604645729065\n",
      "iter:290 reconstructive loss:0.45843201875686646\n",
      "iter:300 reconstructive loss:0.45413708686828613\n",
      "iter:310 reconstructive loss:0.4540523290634155\n",
      "iter:320 reconstructive loss:0.4501643776893616\n",
      "iter:330 reconstructive loss:0.4512394070625305\n",
      "iter:340 reconstructive loss:0.4463823139667511\n",
      "iter:350 reconstructive loss:0.4426071047782898\n",
      "iter:360 reconstructive loss:0.44016382098197937\n",
      "iter:370 reconstructive loss:0.4400204122066498\n",
      "iter:380 reconstructive loss:0.4388594627380371\n",
      "iter:390 reconstructive loss:0.43544840812683105\n",
      "iter:400 reconstructive loss:0.43351563811302185\n",
      "iter:410 reconstructive loss:0.43159571290016174\n",
      "iter:420 reconstructive loss:0.42994046211242676\n",
      "iter:430 reconstructive loss:0.42824259400367737\n",
      "iter:440 reconstructive loss:0.427340030670166\n",
      "iter:450 reconstructive loss:0.4229869246482849\n",
      "iter:460 reconstructive loss:0.42418354749679565\n",
      "iter:470 reconstructive loss:0.42352044582366943\n",
      "iter:480 reconstructive loss:0.4216233193874359\n",
      "iter:490 reconstructive loss:0.41908952593803406\n",
      "iter:500 reconstructive loss:0.41840654611587524\n",
      "iter:510 reconstructive loss:0.41462478041648865\n",
      "iter:520 reconstructive loss:0.4125218391418457\n",
      "iter:530 reconstructive loss:0.4092681407928467\n",
      "iter:540 reconstructive loss:0.4118399918079376\n",
      "iter:550 reconstructive loss:0.4099276661872864\n",
      "iter:560 reconstructive loss:0.4051104187965393\n",
      "iter:570 reconstructive loss:0.40581953525543213\n",
      "iter:580 reconstructive loss:0.4040961265563965\n",
      "iter:590 reconstructive loss:0.4028387665748596\n",
      "iter:600 reconstructive loss:0.400671124458313\n",
      "iter:610 reconstructive loss:0.39812636375427246\n",
      "iter:620 reconstructive loss:0.3990226686000824\n",
      "iter:630 reconstructive loss:0.39562952518463135\n",
      "iter:640 reconstructive loss:0.39546290040016174\n",
      "iter:650 reconstructive loss:0.39186859130859375\n",
      "iter:660 reconstructive loss:0.39141201972961426\n",
      "iter:670 reconstructive loss:0.38998082280158997\n",
      "iter:680 reconstructive loss:0.387418270111084\n",
      "iter:690 reconstructive loss:0.38830751180648804\n",
      "iter:700 reconstructive loss:0.3855202794075012\n",
      "iter:710 reconstructive loss:0.385751336812973\n",
      "iter:720 reconstructive loss:0.3854217529296875\n",
      "iter:730 reconstructive loss:0.38294267654418945\n",
      "iter:740 reconstructive loss:0.3812834918498993\n",
      "iter:750 reconstructive loss:0.3794856071472168\n",
      "iter:760 reconstructive loss:0.37843865156173706\n",
      "iter:770 reconstructive loss:0.3761492371559143\n",
      "iter:780 reconstructive loss:0.37520426511764526\n",
      "iter:790 reconstructive loss:0.3751356601715088\n",
      "iter:800 reconstructive loss:0.37416142225265503\n",
      "iter:810 reconstructive loss:0.3718452453613281\n",
      "iter:820 reconstructive loss:0.37053704261779785\n",
      "iter:830 reconstructive loss:0.37020343542099\n",
      "iter:840 reconstructive loss:0.3690206706523895\n",
      "iter:850 reconstructive loss:0.3667669892311096\n",
      "iter:860 reconstructive loss:0.36708682775497437\n",
      "iter:870 reconstructive loss:0.3656524121761322\n",
      "iter:880 reconstructive loss:0.36302900314331055\n",
      "iter:890 reconstructive loss:0.3632757067680359\n",
      "iter:900 reconstructive loss:0.36133724451065063\n",
      "iter:910 reconstructive loss:0.35949626564979553\n",
      "iter:920 reconstructive loss:0.3590283989906311\n",
      "iter:930 reconstructive loss:0.3579816222190857\n",
      "iter:940 reconstructive loss:0.3576502203941345\n",
      "iter:950 reconstructive loss:0.3570931553840637\n",
      "iter:960 reconstructive loss:0.3554701507091522\n",
      "iter:970 reconstructive loss:0.3549066185951233\n",
      "iter:980 reconstructive loss:0.35292893648147583\n",
      "iter:990 reconstructive loss:0.3522173762321472\n",
      "iter:1000 reconstructive loss:0.3522396683692932\n",
      "Saved Model\n",
      "iter:1010 reconstructive loss:0.3508548140525818\n",
      "iter:1020 reconstructive loss:0.3499476909637451\n",
      "iter:1030 reconstructive loss:0.3482457995414734\n",
      "iter:1040 reconstructive loss:0.34773147106170654\n",
      "iter:1050 reconstructive loss:0.34630125761032104\n",
      "iter:1060 reconstructive loss:0.34612464904785156\n",
      "iter:1070 reconstructive loss:0.3456799387931824\n",
      "iter:1080 reconstructive loss:0.34535714983940125\n",
      "iter:1090 reconstructive loss:0.34367138147354126\n",
      "iter:1100 reconstructive loss:0.34300142526626587\n",
      "iter:1110 reconstructive loss:0.34140902757644653\n",
      "iter:1120 reconstructive loss:0.3400796055793762\n",
      "iter:1130 reconstructive loss:0.34087544679641724\n",
      "iter:1140 reconstructive loss:0.33836886286735535\n",
      "iter:1150 reconstructive loss:0.33931368589401245\n",
      "iter:1160 reconstructive loss:0.33837148547172546\n",
      "iter:1170 reconstructive loss:0.3366219103336334\n",
      "iter:1180 reconstructive loss:0.3349413275718689\n",
      "iter:1190 reconstructive loss:0.33519017696380615\n",
      "iter:1200 reconstructive loss:0.33371081948280334\n",
      "iter:1210 reconstructive loss:0.3340242803096771\n",
      "iter:1220 reconstructive loss:0.3329702615737915\n",
      "iter:1230 reconstructive loss:0.3322182595729828\n",
      "iter:1240 reconstructive loss:0.3306525945663452\n",
      "iter:1250 reconstructive loss:0.3303256034851074\n",
      "iter:1260 reconstructive loss:0.3295323848724365\n",
      "iter:1270 reconstructive loss:0.3289083242416382\n",
      "iter:1280 reconstructive loss:0.32807332277297974\n",
      "iter:1290 reconstructive loss:0.3273048996925354\n",
      "iter:1300 reconstructive loss:0.32692229747772217\n",
      "iter:1310 reconstructive loss:0.32614946365356445\n",
      "iter:1320 reconstructive loss:0.3267020583152771\n",
      "iter:1330 reconstructive loss:0.32533198595046997\n",
      "iter:1340 reconstructive loss:0.323830246925354\n",
      "iter:1350 reconstructive loss:0.32391345500946045\n",
      "iter:1360 reconstructive loss:0.32270678877830505\n",
      "iter:1370 reconstructive loss:0.32262077927589417\n",
      "iter:1380 reconstructive loss:0.3217003047466278\n",
      "iter:1390 reconstructive loss:0.32115820050239563\n",
      "iter:1400 reconstructive loss:0.32112938165664673\n",
      "iter:1410 reconstructive loss:0.3204312026500702\n",
      "iter:1420 reconstructive loss:0.3199201822280884\n",
      "iter:1430 reconstructive loss:0.31875401735305786\n",
      "iter:1440 reconstructive loss:0.31804800033569336\n",
      "iter:1450 reconstructive loss:0.31738346815109253\n",
      "iter:1460 reconstructive loss:0.31710386276245117\n",
      "iter:1470 reconstructive loss:0.31645235419273376\n",
      "iter:1480 reconstructive loss:0.31594401597976685\n",
      "iter:1490 reconstructive loss:0.3153683543205261\n",
      "iter:1500 reconstructive loss:0.3148282766342163\n",
      "iter:1510 reconstructive loss:0.31388822197914124\n",
      "iter:1520 reconstructive loss:0.3136643171310425\n",
      "iter:1530 reconstructive loss:0.3133484423160553\n",
      "iter:1540 reconstructive loss:0.31326818466186523\n",
      "iter:1550 reconstructive loss:0.3123292326927185\n",
      "iter:1560 reconstructive loss:0.311629056930542\n",
      "iter:1570 reconstructive loss:0.3114141821861267\n",
      "iter:1580 reconstructive loss:0.31074827909469604\n",
      "iter:1590 reconstructive loss:0.3101632297039032\n",
      "iter:1600 reconstructive loss:0.3094329535961151\n",
      "iter:1610 reconstructive loss:0.3091399371623993\n",
      "iter:1620 reconstructive loss:0.3084579408168793\n",
      "iter:1630 reconstructive loss:0.3083661198616028\n",
      "iter:1640 reconstructive loss:0.3074902296066284\n",
      "iter:1650 reconstructive loss:0.30735188722610474\n",
      "iter:1660 reconstructive loss:0.306705117225647\n",
      "iter:1670 reconstructive loss:0.30638518929481506\n",
      "iter:1680 reconstructive loss:0.3058222532272339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:1690 reconstructive loss:0.3055158257484436\n",
      "iter:1700 reconstructive loss:0.30510789155960083\n",
      "iter:1710 reconstructive loss:0.30444639921188354\n",
      "iter:1720 reconstructive loss:0.3040725290775299\n",
      "iter:1730 reconstructive loss:0.3037272095680237\n",
      "iter:1740 reconstructive loss:0.30314821004867554\n",
      "iter:1750 reconstructive loss:0.30300599336624146\n",
      "iter:1760 reconstructive loss:0.3025512099266052\n",
      "iter:1770 reconstructive loss:0.30201685428619385\n",
      "iter:1780 reconstructive loss:0.3015842139720917\n",
      "iter:1790 reconstructive loss:0.30145689845085144\n",
      "iter:1800 reconstructive loss:0.3008890748023987\n",
      "iter:1810 reconstructive loss:0.3005110025405884\n",
      "iter:1820 reconstructive loss:0.300409734249115\n",
      "iter:1830 reconstructive loss:0.29975390434265137\n",
      "iter:1840 reconstructive loss:0.2993970215320587\n",
      "iter:1850 reconstructive loss:0.29910844564437866\n",
      "iter:1860 reconstructive loss:0.2987583875656128\n",
      "iter:1870 reconstructive loss:0.2981300354003906\n",
      "iter:1880 reconstructive loss:0.297815203666687\n",
      "iter:1890 reconstructive loss:0.2976616621017456\n",
      "iter:1900 reconstructive loss:0.29738548398017883\n",
      "iter:1910 reconstructive loss:0.2971384525299072\n",
      "iter:1920 reconstructive loss:0.296653687953949\n",
      "iter:1930 reconstructive loss:0.2961566150188446\n",
      "iter:1940 reconstructive loss:0.29586508870124817\n",
      "iter:1950 reconstructive loss:0.2954290807247162\n",
      "iter:1960 reconstructive loss:0.29538655281066895\n",
      "iter:1970 reconstructive loss:0.2950296401977539\n",
      "iter:1980 reconstructive loss:0.29485005140304565\n",
      "iter:1990 reconstructive loss:0.29443371295928955\n",
      "iter:2000 reconstructive loss:0.29379457235336304\n",
      "Saved Model\n",
      "iter:2010 reconstructive loss:0.2935301661491394\n",
      "iter:2020 reconstructive loss:0.2931596636772156\n",
      "iter:2030 reconstructive loss:0.293230801820755\n",
      "iter:2040 reconstructive loss:0.29278504848480225\n",
      "iter:2050 reconstructive loss:0.2925599217414856\n",
      "iter:2060 reconstructive loss:0.2920544743537903\n",
      "iter:2070 reconstructive loss:0.2922707498073578\n",
      "iter:2080 reconstructive loss:0.29167452454566956\n",
      "iter:2090 reconstructive loss:0.29146140813827515\n",
      "iter:2100 reconstructive loss:0.29092690348625183\n",
      "iter:2110 reconstructive loss:0.291067510843277\n",
      "iter:2120 reconstructive loss:0.29038116335868835\n",
      "iter:2130 reconstructive loss:0.2901870012283325\n",
      "iter:2140 reconstructive loss:0.2897544503211975\n",
      "iter:2150 reconstructive loss:0.2896422743797302\n",
      "iter:2160 reconstructive loss:0.2892307639122009\n",
      "iter:2170 reconstructive loss:0.28974881768226624\n",
      "iter:2180 reconstructive loss:0.2890387773513794\n",
      "iter:2190 reconstructive loss:0.2887433171272278\n",
      "iter:2200 reconstructive loss:0.2884950339794159\n",
      "iter:2210 reconstructive loss:0.2883720397949219\n",
      "iter:2220 reconstructive loss:0.28815892338752747\n",
      "iter:2230 reconstructive loss:0.2879895269870758\n",
      "iter:2240 reconstructive loss:0.28765547275543213\n",
      "iter:2250 reconstructive loss:0.2871435284614563\n",
      "iter:2260 reconstructive loss:0.2870635688304901\n",
      "iter:2270 reconstructive loss:0.2863098382949829\n",
      "iter:2280 reconstructive loss:0.2865884304046631\n",
      "iter:2290 reconstructive loss:0.28611981868743896\n",
      "iter:2300 reconstructive loss:0.28585052490234375\n",
      "iter:2310 reconstructive loss:0.285642147064209\n",
      "iter:2320 reconstructive loss:0.28553348779678345\n",
      "iter:2330 reconstructive loss:0.2850896120071411\n",
      "iter:2340 reconstructive loss:0.28461918234825134\n",
      "iter:2350 reconstructive loss:0.28525376319885254\n",
      "iter:2360 reconstructive loss:0.2848171591758728\n",
      "iter:2370 reconstructive loss:0.2842678129673004\n",
      "iter:2380 reconstructive loss:0.28422752022743225\n",
      "iter:2390 reconstructive loss:0.2837024927139282\n",
      "iter:2400 reconstructive loss:0.28451043367385864\n",
      "iter:2410 reconstructive loss:0.28411024808883667\n",
      "iter:2420 reconstructive loss:0.2837095856666565\n",
      "iter:2430 reconstructive loss:0.28332042694091797\n",
      "iter:2440 reconstructive loss:0.2832179665565491\n",
      "iter:2450 reconstructive loss:0.2825789749622345\n",
      "iter:2460 reconstructive loss:0.2830330729484558\n",
      "iter:2470 reconstructive loss:0.28254759311676025\n",
      "iter:2480 reconstructive loss:0.28284063935279846\n",
      "iter:2490 reconstructive loss:0.2820933759212494\n",
      "iter:2500 reconstructive loss:0.2822555899620056\n",
      "iter:2510 reconstructive loss:0.2821999788284302\n",
      "iter:2520 reconstructive loss:0.28155699372291565\n",
      "iter:2530 reconstructive loss:0.28141939640045166\n",
      "iter:2540 reconstructive loss:0.2810814082622528\n",
      "iter:2550 reconstructive loss:0.2813372015953064\n",
      "iter:2560 reconstructive loss:0.2811558246612549\n",
      "iter:2570 reconstructive loss:0.2804805636405945\n",
      "iter:2580 reconstructive loss:0.28034934401512146\n",
      "iter:2590 reconstructive loss:0.2811600863933563\n",
      "iter:2600 reconstructive loss:0.28023475408554077\n",
      "iter:2610 reconstructive loss:0.28034788370132446\n",
      "iter:2620 reconstructive loss:0.2794575095176697\n",
      "iter:2630 reconstructive loss:0.2793961763381958\n",
      "iter:2640 reconstructive loss:0.27992504835128784\n",
      "iter:2650 reconstructive loss:0.28032031655311584\n",
      "iter:2660 reconstructive loss:0.27923136949539185\n",
      "iter:2670 reconstructive loss:0.2793797254562378\n",
      "iter:2680 reconstructive loss:0.2786638140678406\n",
      "iter:2690 reconstructive loss:0.27862897515296936\n",
      "iter:2700 reconstructive loss:0.2785493731498718\n",
      "iter:2710 reconstructive loss:0.27889180183410645\n",
      "iter:2720 reconstructive loss:0.2783648371696472\n",
      "iter:2730 reconstructive loss:0.2784271240234375\n",
      "iter:2740 reconstructive loss:0.2772371768951416\n",
      "iter:2750 reconstructive loss:0.27837854623794556\n",
      "iter:2760 reconstructive loss:0.27801764011383057\n",
      "iter:2770 reconstructive loss:0.2785513699054718\n",
      "iter:2780 reconstructive loss:0.2771952748298645\n",
      "iter:2790 reconstructive loss:0.27778512239456177\n",
      "iter:2800 reconstructive loss:0.2772521674633026\n",
      "iter:2810 reconstructive loss:0.2771928012371063\n",
      "iter:2820 reconstructive loss:0.27782168984413147\n",
      "iter:2830 reconstructive loss:0.27790936827659607\n",
      "iter:2840 reconstructive loss:0.2768280804157257\n",
      "iter:2850 reconstructive loss:0.2764819264411926\n",
      "iter:2860 reconstructive loss:0.277974009513855\n",
      "iter:2870 reconstructive loss:0.2763495445251465\n",
      "iter:2880 reconstructive loss:0.27606168389320374\n",
      "iter:2890 reconstructive loss:0.27666404843330383\n",
      "iter:2900 reconstructive loss:0.27601125836372375\n",
      "iter:2910 reconstructive loss:0.2761285901069641\n",
      "iter:2920 reconstructive loss:0.2758316993713379\n",
      "iter:2930 reconstructive loss:0.27513206005096436\n",
      "iter:2940 reconstructive loss:0.27548646926879883\n",
      "iter:2950 reconstructive loss:0.2745133936405182\n",
      "iter:2960 reconstructive loss:0.2769600749015808\n",
      "iter:2970 reconstructive loss:0.27517274022102356\n",
      "iter:2980 reconstructive loss:0.276434063911438\n",
      "iter:2990 reconstructive loss:0.2756391167640686\n",
      "iter:3000 reconstructive loss:0.2750600278377533\n",
      "Saved Model\n",
      "iter:3010 reconstructive loss:0.2757125794887543\n",
      "iter:3020 reconstructive loss:0.27440276741981506\n",
      "iter:3030 reconstructive loss:0.274513304233551\n",
      "iter:3040 reconstructive loss:0.27474719285964966\n",
      "iter:3050 reconstructive loss:0.2748250961303711\n",
      "iter:3060 reconstructive loss:0.27400922775268555\n",
      "iter:3070 reconstructive loss:0.27335578203201294\n",
      "iter:3080 reconstructive loss:0.2738311290740967\n",
      "iter:3090 reconstructive loss:0.27517324686050415\n",
      "iter:3100 reconstructive loss:0.2741473913192749\n",
      "iter:3110 reconstructive loss:0.27362605929374695\n",
      "iter:3120 reconstructive loss:0.2737446427345276\n",
      "iter:3130 reconstructive loss:0.27327969670295715\n",
      "iter:3140 reconstructive loss:0.2740074098110199\n",
      "iter:3150 reconstructive loss:0.2735632658004761\n",
      "iter:3160 reconstructive loss:0.2730787396430969\n",
      "iter:3170 reconstructive loss:0.2723020613193512\n",
      "iter:3180 reconstructive loss:0.27309682965278625\n",
      "iter:3190 reconstructive loss:0.2743844985961914\n",
      "iter:3200 reconstructive loss:0.2721853256225586\n",
      "iter:3210 reconstructive loss:0.27206170558929443\n",
      "iter:3220 reconstructive loss:0.2721555531024933\n",
      "iter:3230 reconstructive loss:0.27248913049697876\n",
      "iter:3240 reconstructive loss:0.2726370692253113\n",
      "iter:3250 reconstructive loss:0.2722321152687073\n",
      "iter:3260 reconstructive loss:0.2726708948612213\n",
      "iter:3270 reconstructive loss:0.2730425000190735\n",
      "iter:3280 reconstructive loss:0.27263975143432617\n",
      "iter:3290 reconstructive loss:0.2719954252243042\n",
      "iter:3300 reconstructive loss:0.27202165126800537\n",
      "iter:3310 reconstructive loss:0.27219000458717346\n",
      "iter:3320 reconstructive loss:0.2729945778846741\n",
      "iter:3330 reconstructive loss:0.271295428276062\n",
      "iter:3340 reconstructive loss:0.2712997794151306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:3350 reconstructive loss:0.2717318534851074\n",
      "iter:3360 reconstructive loss:0.2710052728652954\n",
      "iter:3370 reconstructive loss:0.27233219146728516\n",
      "iter:3380 reconstructive loss:0.2714363932609558\n",
      "iter:3390 reconstructive loss:0.27307552099227905\n",
      "iter:3400 reconstructive loss:0.27155426144599915\n",
      "iter:3410 reconstructive loss:0.27121204137802124\n",
      "iter:3420 reconstructive loss:0.2705214321613312\n",
      "iter:3430 reconstructive loss:0.272163987159729\n",
      "iter:3440 reconstructive loss:0.27083253860473633\n",
      "iter:3450 reconstructive loss:0.27075058221817017\n",
      "iter:3460 reconstructive loss:0.2712263762950897\n",
      "iter:3470 reconstructive loss:0.2709067761898041\n",
      "iter:3480 reconstructive loss:0.27263015508651733\n",
      "iter:3490 reconstructive loss:0.26961201429367065\n",
      "iter:3500 reconstructive loss:0.2708171606063843\n",
      "iter:3510 reconstructive loss:0.2708665132522583\n",
      "iter:3520 reconstructive loss:0.2705356478691101\n",
      "iter:3530 reconstructive loss:0.27182847261428833\n",
      "iter:3540 reconstructive loss:0.27122825384140015\n",
      "iter:3550 reconstructive loss:0.2709418535232544\n",
      "iter:3560 reconstructive loss:0.27114009857177734\n",
      "iter:3570 reconstructive loss:0.2705167531967163\n",
      "iter:3580 reconstructive loss:0.271026074886322\n",
      "iter:3590 reconstructive loss:0.27159684896469116\n",
      "iter:3600 reconstructive loss:0.2709942162036896\n",
      "iter:3610 reconstructive loss:0.27079692482948303\n",
      "iter:3620 reconstructive loss:0.2702006697654724\n",
      "iter:3630 reconstructive loss:0.2690817415714264\n",
      "iter:3640 reconstructive loss:0.2692393958568573\n",
      "iter:3650 reconstructive loss:0.2698654234409332\n",
      "iter:3660 reconstructive loss:0.27007266879081726\n",
      "iter:3670 reconstructive loss:0.2703618109226227\n",
      "iter:3680 reconstructive loss:0.2705444395542145\n",
      "iter:3690 reconstructive loss:0.26993125677108765\n",
      "iter:3700 reconstructive loss:0.2691516876220703\n",
      "iter:3710 reconstructive loss:0.26988163590431213\n",
      "iter:3720 reconstructive loss:0.26984065771102905\n",
      "iter:3730 reconstructive loss:0.27086031436920166\n",
      "iter:3740 reconstructive loss:0.268635094165802\n",
      "iter:3750 reconstructive loss:0.27102816104888916\n",
      "iter:3760 reconstructive loss:0.26929184794425964\n",
      "iter:3770 reconstructive loss:0.2691397964954376\n",
      "iter:3780 reconstructive loss:0.2683103084564209\n",
      "iter:3790 reconstructive loss:0.2685316205024719\n",
      "iter:3800 reconstructive loss:0.2682962417602539\n",
      "iter:3810 reconstructive loss:0.26867052912712097\n",
      "iter:3820 reconstructive loss:0.26876914501190186\n",
      "iter:3830 reconstructive loss:0.2687228322029114\n",
      "iter:3840 reconstructive loss:0.2678816318511963\n",
      "iter:3850 reconstructive loss:0.2677161693572998\n",
      "iter:3860 reconstructive loss:0.26869192719459534\n",
      "iter:3870 reconstructive loss:0.2686046361923218\n",
      "iter:3880 reconstructive loss:0.268302857875824\n",
      "iter:3890 reconstructive loss:0.26847007870674133\n",
      "iter:3900 reconstructive loss:0.26847749948501587\n",
      "iter:3910 reconstructive loss:0.26920759677886963\n",
      "iter:3920 reconstructive loss:0.26770180463790894\n",
      "iter:3930 reconstructive loss:0.2695760726928711\n",
      "iter:3940 reconstructive loss:0.2684616148471832\n",
      "iter:3950 reconstructive loss:0.2692868411540985\n",
      "iter:3960 reconstructive loss:0.2687684893608093\n",
      "iter:3970 reconstructive loss:0.2688295245170593\n",
      "iter:3980 reconstructive loss:0.26839104294776917\n",
      "iter:3990 reconstructive loss:0.2691004276275635\n",
      "iter:4000 reconstructive loss:0.26767635345458984\n",
      "Saved Model\n",
      "iter:4010 reconstructive loss:0.2693617045879364\n",
      "iter:4020 reconstructive loss:0.2683227062225342\n",
      "iter:4030 reconstructive loss:0.26831626892089844\n",
      "iter:4040 reconstructive loss:0.2689506411552429\n",
      "iter:4050 reconstructive loss:0.2690013349056244\n",
      "iter:4060 reconstructive loss:0.2691064178943634\n",
      "iter:4070 reconstructive loss:0.267953097820282\n",
      "iter:4080 reconstructive loss:0.26707762479782104\n",
      "iter:4090 reconstructive loss:0.2668798267841339\n",
      "iter:4100 reconstructive loss:0.2683165669441223\n",
      "iter:4110 reconstructive loss:0.2689312696456909\n",
      "iter:4120 reconstructive loss:0.2685355544090271\n",
      "iter:4130 reconstructive loss:0.26892098784446716\n",
      "iter:4140 reconstructive loss:0.2690782845020294\n",
      "iter:4150 reconstructive loss:0.26806843280792236\n",
      "iter:4160 reconstructive loss:0.2680853009223938\n",
      "iter:4170 reconstructive loss:0.26603537797927856\n",
      "iter:4180 reconstructive loss:0.2683448791503906\n",
      "iter:4190 reconstructive loss:0.2674145996570587\n",
      "iter:4200 reconstructive loss:0.2674744725227356\n",
      "iter:4210 reconstructive loss:0.26661553978919983\n",
      "iter:4220 reconstructive loss:0.2685973644256592\n",
      "iter:4230 reconstructive loss:0.26885855197906494\n",
      "iter:4240 reconstructive loss:0.26872003078460693\n",
      "iter:4250 reconstructive loss:0.26858237385749817\n",
      "iter:4260 reconstructive loss:0.26785793900489807\n",
      "iter:4270 reconstructive loss:0.26863953471183777\n",
      "iter:4280 reconstructive loss:0.2675837278366089\n",
      "iter:4290 reconstructive loss:0.26688820123672485\n",
      "iter:4300 reconstructive loss:0.2700585722923279\n",
      "iter:4310 reconstructive loss:0.26727110147476196\n",
      "iter:4320 reconstructive loss:0.26885515451431274\n",
      "iter:4330 reconstructive loss:0.26898497343063354\n",
      "iter:4340 reconstructive loss:0.2680659890174866\n",
      "iter:4350 reconstructive loss:0.2668626308441162\n",
      "iter:4360 reconstructive loss:0.2673569619655609\n",
      "iter:4370 reconstructive loss:0.2659153342247009\n",
      "iter:4380 reconstructive loss:0.26813817024230957\n",
      "iter:4390 reconstructive loss:0.26804041862487793\n",
      "iter:4400 reconstructive loss:0.2679952383041382\n",
      "iter:4410 reconstructive loss:0.26844120025634766\n",
      "iter:4420 reconstructive loss:0.26692360639572144\n",
      "iter:4430 reconstructive loss:0.2673363983631134\n",
      "iter:4440 reconstructive loss:0.26660647988319397\n",
      "iter:4450 reconstructive loss:0.26828575134277344\n",
      "iter:4460 reconstructive loss:0.2681688070297241\n",
      "iter:4470 reconstructive loss:0.2673114836215973\n",
      "iter:4480 reconstructive loss:0.26739034056663513\n",
      "iter:4490 reconstructive loss:0.26683205366134644\n",
      "iter:4500 reconstructive loss:0.2664968967437744\n",
      "iter:4510 reconstructive loss:0.2673278748989105\n",
      "iter:4520 reconstructive loss:0.2663523852825165\n",
      "iter:4530 reconstructive loss:0.26592913269996643\n",
      "iter:4540 reconstructive loss:0.2678026556968689\n",
      "iter:4550 reconstructive loss:0.2678329348564148\n",
      "iter:4560 reconstructive loss:0.2689824402332306\n",
      "iter:4570 reconstructive loss:0.26820147037506104\n",
      "iter:4580 reconstructive loss:0.267071008682251\n",
      "iter:4590 reconstructive loss:0.2667342722415924\n",
      "iter:4600 reconstructive loss:0.26516592502593994\n",
      "iter:4610 reconstructive loss:0.26595526933670044\n",
      "iter:4620 reconstructive loss:0.26612287759780884\n",
      "iter:4630 reconstructive loss:0.2677733898162842\n",
      "iter:4640 reconstructive loss:0.267184853553772\n",
      "iter:4650 reconstructive loss:0.26572614908218384\n",
      "iter:4660 reconstructive loss:0.26598721742630005\n",
      "iter:4670 reconstructive loss:0.2671036720275879\n",
      "iter:4680 reconstructive loss:0.2664029002189636\n",
      "iter:4690 reconstructive loss:0.26612603664398193\n",
      "iter:4700 reconstructive loss:0.2652846574783325\n",
      "iter:4710 reconstructive loss:0.26879173517227173\n",
      "iter:4720 reconstructive loss:0.26626133918762207\n",
      "iter:4730 reconstructive loss:0.26548561453819275\n",
      "iter:4740 reconstructive loss:0.2660899758338928\n",
      "iter:4750 reconstructive loss:0.2666405439376831\n",
      "iter:4760 reconstructive loss:0.2670934796333313\n",
      "iter:4770 reconstructive loss:0.2642146348953247\n",
      "iter:4780 reconstructive loss:0.2675849199295044\n",
      "iter:4790 reconstructive loss:0.26648497581481934\n",
      "iter:4800 reconstructive loss:0.26778507232666016\n",
      "iter:4810 reconstructive loss:0.26859045028686523\n",
      "iter:4820 reconstructive loss:0.2673129439353943\n",
      "iter:4830 reconstructive loss:0.2671056091785431\n",
      "iter:4840 reconstructive loss:0.2658831477165222\n",
      "iter:4850 reconstructive loss:0.26590120792388916\n",
      "iter:4860 reconstructive loss:0.26737040281295776\n",
      "iter:4870 reconstructive loss:0.26771843433380127\n",
      "iter:4880 reconstructive loss:0.2655789852142334\n",
      "iter:4890 reconstructive loss:0.2662917375564575\n",
      "iter:4900 reconstructive loss:0.267645925283432\n",
      "iter:4910 reconstructive loss:0.2655797302722931\n",
      "iter:4920 reconstructive loss:0.26592567563056946\n",
      "iter:4930 reconstructive loss:0.26547902822494507\n",
      "iter:4940 reconstructive loss:0.2694269120693207\n",
      "iter:4950 reconstructive loss:0.26708540320396423\n",
      "iter:4960 reconstructive loss:0.26512300968170166\n",
      "iter:4970 reconstructive loss:0.2673041820526123\n",
      "iter:4980 reconstructive loss:0.2663276791572571\n",
      "iter:4990 reconstructive loss:0.26612067222595215\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "batch_size = 128 #Size of image batch to apply at each iteration.\n",
    "iterations = 5000 #Total number of iterations to use.\n",
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to save trained model to.\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        xs,_ = mnist.train.next_batch(batch_size)\n",
    "        xs = (np.reshape(xs,[batch_size,28,28,1]) ) \n",
    "        xs = np.lib.pad(xs, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1))\n",
    "        _,train_loss, x_re = sess.run([optimizer, loss, xp], feed_dict = {img_in:xs})\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"iter:{} reconstructive loss:{}\".format(i,train_loss))\n",
    "\n",
    "            if not os.path.exists(sample_directory):\n",
    "                    os.makedirs(sample_directory)\n",
    "        \n",
    "            #save_images(x_re, [32,32] ,sample_directory+'/fig'+str(i)+'.png')\n",
    "            save_images(np.reshape(x_re[0:36],[36,32,32]),[6,6],sample_directory+'/fig'+str(i)+'.png')\n",
    "            if i % 1000 == 0 and i != 0:\n",
    "                if not os.path.exists(model_directory):\n",
    "                    os.makedirs(model_directory)\n",
    "                saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
    "                print(\"Saved Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "INFO:tensorflow:Restoring parameters from ./models\\model-4000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#infer\n",
    "\n",
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to load trained model from.\n",
    "batch_size_sample = 36\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    #Reload the model.\n",
    "    print('Loading Model...')\n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    \n",
    "     #Generate a random z batch\n",
    "    xs,_ = mnist.validation.next_batch(batch_size)\n",
    "    xs = (np.reshape(xs,[batch_size,28,28,1]) ) \n",
    "    xs = np.lib.pad(xs, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1))\n",
    "    x_re = sess.run(xp,feed_dict={img_in:xs}) #Use new z to get sample images from generator.\n",
    "    if not os.path.exists(sample_directory):\n",
    "        os.makedirs(sample_directory)\n",
    "    save_images(np.reshape(x_re[0:batch_size_sample],[36,32,32]),[6,6],sample_directory+'/infer.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
